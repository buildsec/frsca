apiVersion: apps/v1
kind: Deployment
metadata:
  labels:
    {{- include "policy-controller.labels" . | nindent 4 }}
    control-plane: {{ template "policy-controller.fullname" . }}-webhook
  name: {{ template "policy-controller.fullname" . }}-webhook
  namespace: {{ .Release.Namespace }}
spec:
  replicas: {{ .Values.webhook.replicaCount }}
  selector:
    matchLabels:
      {{- include "policy-controller.selectorLabels" . | nindent 6 }}
      control-plane: {{ template "policy-controller.fullname" . }}-webhook
  template:
    metadata:
      labels:
        {{- include "policy-controller.selectorLabels" . | nindent 8 }}
        control-plane: {{ template "policy-controller.fullname" . }}-webhook
    spec:
      nodeSelector:
        {{- toYaml .Values.commonNodeSelector | nindent 8 }}
      {{- if .Values.imagePullSecrets }}
      imagePullSecrets:
{{ toYaml .Values.imagePullSecrets | indent 8 }}
      {{- end }}
      tolerations:
        {{- toYaml .Values.commonTolerations | nindent 8 }}
      serviceAccountName: {{ template "policy-controller.fullname" . }}-webhook
      # To avoid node becoming SPOF, spread our replicas to different nodes.
      affinity:
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
          - podAffinityTerm:
              labelSelector:
                matchLabels:
                  control-plane: {{ template "policy-controller.fullname" . }}-webhook
              topologyKey: kubernetes.io/hostname
            weight: 100
      containers:
      - name: {{ template "policy-controller.name" . }}-{{ .Values.webhook.name }}
        image: "{{ template "policy-controller.image" .Values.webhook.image }}"
        imagePullPolicy: "{{ .Values.webhook.image.pullPolicy }}"
        env:
        - name: SYSTEM_NAMESPACE
          valueFrom:
            fieldRef:
              fieldPath: metadata.namespace
        - name: CONFIG_LOGGING_NAME
          value: {{ template "policy-controller.fullname" . }}-webhook-logging
        - name: CONFIG_OBSERVABILITY_NAME
          value: {{ template "policy-controller.fullname" . }}-webhook-observability
        - name: METRICS_DOMAIN
          value: sigstore.dev/policy
        - name: WEBHOOK_NAME
          value: webhook
        - name: HOME
          value: /home/nonroot
        {{- if .Values.webhook.registryCaBundle.name }}
        - name: SSL_CERT_DIR
          value: /etc/custom-ca:/etc/ssl/certs
        {{- end }}
{{- if .Values.webhook.env }}
{{- range $key, $value := .Values.webhook.env }}
        - name: "{{ $key }}"
          value: "{{ $value }}"
{{- end }}
{{- end }}
        args:
        {{- if semverCompare ">= 1.8-0" .Chart.AppVersion }}
        - -webhook-name={{ required "A valid cosign.webhookName is required" .Values.cosign.webhookName }}
        {{- end }}
        {{- range $key, $value := .Values.webhook.extraArgs }}
        - -{{ $key }}={{ $value }}
        {{- end }}
        ports:
        - containerPort: 8443
          name: https
          protocol: TCP
        - containerPort: 9090
          name: metrics
          protocol: TCP
        resources:
        {{- with .Values.webhook.resources }}
          {{- toYaml . | nindent 10 }}
        {{- end }}
        livenessProbe:
          failureThreshold: 6
          initialDelaySeconds: 30
          periodSeconds: 1
          httpGet:
            port: 8443
            scheme: HTTPS
            path: /healthz
            httpHeaders:
            - name: k-kubelet-probe
              value: "webhook"
        readinessProbe:
          failureThreshold: 6
          initialDelaySeconds: 20
          periodSeconds: 1
          httpGet:
            port: 8443
            scheme: HTTPS
            path: /readyz
            httpHeaders:
            - name: k-kubelet-probe
              value: "webhook"
{{- if .Values.webhook.podSecurityContext.enabled }}
        securityContext:
        {{- with .Values.webhook.podSecurityContext }}
        {{- omit . "enabled" | toYaml | nindent 10}}
        {{- end }}
{{- end }}
        volumeMounts:
          # Failing to provide a writable $HOME can cause TUF client initialization to panic
          - mountPath: /home/nonroot
            name: writable-home-dir
          {{- with .Values.webhook.volumeMounts }}
            {{- toYaml . | nindent 10 }}
          {{- end }}
          {{- if .Values.webhook.registryCaBundle.name }}
          - mountPath: /etc/custom-ca
            name: custom-ca
            readOnly: true
          {{- end }}
      {{- if .Values.webhook.securityContext.enabled }}

      # Our webhook should gracefully terminate by lame ducking first, set this to a sufficiently
      # high value that we respect whatever value it has configured for the lame duck grace period.
      terminationGracePeriodSeconds: 300

      securityContext:
        {{- with .Values.webhook.securityContext }}
        {{- toYaml . | nindent 8}}
        {{- end }}
      {{- end }}
      volumes:
      - emptyDir: {}
        name: writable-home-dir
      {{- with .Values.webhook.volumes }}
        {{- toYaml . | nindent 6 }}
      {{- end }}
      {{- if .Values.webhook.registryCaBundle.name }}
      - name: custom-ca
        configMap:
          name: {{ .Values.webhook.registryCaBundle.name }}
          items:
            - key: {{ .Values.webhook.registryCaBundle.key }}
              path: {{ .Values.webhook.registryCaBundle.key }}
      {{- end }}
